{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Trident with Your Own Foundation Model \n",
    "\n",
    "As more and more groups design their own foundation model, we want to offer easy tools for custom integration. This is the idea of the `CustomInferenceEncoder` from the `patch_encoder_models` module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "import torch\n",
    "import timm\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from trident.patch_encoder_models.load import CustomInferenceEncoder\n",
    "\n",
    "# Load your custom model (eg ViT pretrained on ImageNet)\n",
    "model = timm.create_model('eva02_large_patch14_448.mim_m38m_ft_in22k_in1k', pretrained=True)\n",
    "model = model.eval()\n",
    "model.head = torch.nn.Identity()  \n",
    "\n",
    "# Set precision\n",
    "precision = torch.float16\n",
    "\n",
    "# Set transforms\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "eval_transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "# Create custom encoder\n",
    "custom_patch_encoder = CustomInferenceEncoder(\n",
    "    enc_name='my_custom_model',\n",
    "    model=model,\n",
    "    transforms=eval_transforms,\n",
    "    precision=precision\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "761eb148c3864c17ad4fb57e030d6dfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 valid slides in /media/ssd/threads/shrimp/tutorials/tutorial-2/wsis.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/guillaume/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Segmenting tissue: 100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 666.93it/s, 394140 already segmented. Skipping...]\n",
      "Saving tissue coordinates to 20x_256px_0px_overlap: 100%|███████████| 1/1 [00:00<00:00,  2.13it/s, Generating patch coords for 394140.svs]\n",
      "/tmp/ipykernel_3064973/1360296154.py:41: DeprecationWarning: Call to deprecated function run_feature_extraction_job.\n",
      "  processor.run_feature_extraction_job(\n",
      "Extracting patch features from coords in 20x_256px_0px_overlap: 100%|██| 1/1 [00:22<00:00, 22.02s/it, Extracting features from 394140.svs]\n"
     ]
    }
   ],
   "source": [
    "# Integrate the above model into Trident \"regular\" pipeline, e.g., using the Processor\n",
    "import os\n",
    "import torch\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "from trident.Processor import Processor\n",
    "from trident.segmentation_models.load import segmentation_model_factory\n",
    "\n",
    "OUTPUT_DIR = \"tutorial-2/\"\n",
    "DEVICE = f\"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "WSI_FNAME = '394140.svs'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "local_wsi_dir = snapshot_download(\n",
    "    repo_id=\"MahmoodLab/unit-testing\",\n",
    "    repo_type='dataset',\n",
    "    local_dir=os.path.join(OUTPUT_DIR, 'wsis'),\n",
    "    allow_patterns=[WSI_FNAME]\n",
    ")\n",
    "\n",
    "# Create processor\n",
    "processor = Processor(\n",
    "    job_dir=OUTPUT_DIR,       # Directory to store outputs\n",
    "    wsi_source=local_wsi_dir, # Directory containing WSI files\n",
    ")\n",
    "\n",
    "# Run tissue vs background segmentation\n",
    "segmentation_model = segmentation_model_factory('hest', device=DEVICE)\n",
    "processor.run_segmentation_job(\n",
    "    segmentation_model,\n",
    "    seg_mag=10\n",
    ")\n",
    "\n",
    "# Run tissue coordinate extraction (256x256 at 20x)\n",
    "processor.run_patching_job(\n",
    "    target_magnification=20,\n",
    "    patch_size=256,\n",
    "    overlap=0\n",
    ")\n",
    "\n",
    "# Run patch feature extraction using the custom encoder\n",
    "processor.run_feature_extraction_job(\n",
    "    coords_dir=f'20x_256px_0px_overlap', # Make sure to change this if you changed the patching parameters\n",
    "    patch_encoder=custom_patch_encoder,\n",
    "    device=DEVICE,\n",
    "    saveas='h5',\n",
    "    batch_limit=32\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trident",
   "language": "python",
   "name": "trident"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
